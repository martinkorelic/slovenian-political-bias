{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3mRyXJABvQm"
      },
      "source": [
        "# Sentimentalna analiza\n",
        "\n",
        "## Okolje\n",
        "\n",
        "Vzpostavitev okolja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bertopic\n",
        "!pip install tweet-preprocessor\n",
        "!pip install classla"
      ],
      "metadata": {
        "id": "5Q5YBNKQrmv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tn4J4JIBulX"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import json\n",
        "import classla\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import os.path\n",
        "#classla.download('sl')\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, pipeline\n",
        "from bertopic import BERTopic\n",
        "import preprocessor as tpre\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSu7MRUkEUDD"
      },
      "outputs": [],
      "source": [
        "# Setting constants\n",
        "\n",
        "LOCAL = False\n",
        "\n",
        "google_data_dir = \"/content/drive/MyDrive/Diploma/Data\"\n",
        "local_data_dir = \"/data\"\n",
        "\n",
        "root_dir = \"\"\n",
        "if LOCAL:\n",
        "    root_dir = local_data_dir\n",
        "else:\n",
        "    root_dir = google_data_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eHCHjqKD4jR"
      },
      "source": [
        "## Funkcije in razredi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUGMXt-RE2mY"
      },
      "outputs": [],
      "source": [
        "def load_tweets(file_name):\n",
        "  # Load data\n",
        "\n",
        "  data = []\n",
        "\n",
        "  with open(file_name, 'r', encoding='utf8') as sample_data:\n",
        "    data = json.load(sample_data)\n",
        "\n",
        "  return data\n",
        "\n",
        "def save_tweets(data, dir, file_name):\n",
        "  with open(f'{dir}/{file_name}.json', 'w+', encoding='utf8') as outdata:\n",
        "    json.dump(data, outdata, ensure_ascii=False)\n",
        "\n",
        "\n",
        "def load_labelled_tweets(dir, topic_names, shuffle_arrays=True, random_state=77):\n",
        "  topics = []\n",
        "  for t in topic_names:\n",
        "    with open(f'{dir}/labelled_topics/topic_{t}.json', 'r', encoding='utf8') as topic_data:\n",
        "      data = json.load(topic_data)\n",
        "      topics.extend(data)\n",
        "  \n",
        "  topic_lemmas = []\n",
        "  topic_labels = []\n",
        "\n",
        "  for t in topics:\n",
        "    topic_lemmas.append(t['lemma_text'])\n",
        "    topic_labels.append(t['topic'])\n",
        "\n",
        "  topic_labels = [ topic_names.index(x) for x in topic_labels]\n",
        "\n",
        "  if shuffle_arrays:\n",
        "    shuffle(topic_lemmas, topic_labels, random_state=random_state)\n",
        "  return topic_lemmas, topic_labels\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Tweetiment Model\n",
        "\n",
        "\"\"\"\n",
        "class TweetimentModel:\n",
        "  def __init__(self, name, model, tokenizer, topic_bias, party_bias):\n",
        "    self.model_name = name\n",
        "\n",
        "    self.topic_bias = topic_bias\n",
        "    self.party_bias = party_bias\n",
        "\n",
        "    self.labels = [\"levo\", \"desno\", \"nevtralno\"]\n",
        "    \n",
        "    self.tokenizer = tokenizer\n",
        "    self.model = model\n",
        "\n",
        "    # Create the pipeline\n",
        "    self.make_model()\n",
        "  \n",
        "  def make_model(self):\n",
        "    self.tweetiment = pipeline(\"sentiment-analysis\", model=self.model, tokenizer=self.tokenizer)\n",
        "\n",
        "  def predict_text(self, txt):\n",
        "    if hasattr(self, 'tweetiment'):\n",
        "      return self.tweetiment(txt)\n",
        "\n",
        "  def classify(self, bias_party, bias_topic):\n",
        "\n",
        "    if bias_party is None and bias_topic is None:\n",
        "      return self.labels[2]\n",
        "    elif bias_party is None:\n",
        "      return bias_topic\n",
        "    elif bias_topic is None:\n",
        "      return bias_party\n",
        "    \n",
        "    return bias_topic\n",
        "\n",
        "  def calculate_biases(self, tweet, explain=False):\n",
        "    if tweet['raw_text']:\n",
        "      prediction = self.predict_text(tweet['raw_text'])[0]\n",
        "\n",
        "      bias_party, party = self.bias_sentiment_party(prediction, tweet)\n",
        "      #bias_user = self.bias_user(prediction)\n",
        "      bias_topic, topic = self.bias_sentiment_topic(prediction, tweet)\n",
        "\n",
        "      if explain:\n",
        "        explanation = self.make_explanation(prediction['label'], bias_party, party, bias_topic, topic)\n",
        "      \n",
        "      label = self.classify(bias_party, bias_topic)\n",
        "\n",
        "      return {\n",
        "          'label': label,\n",
        "          'sentiment': prediction['label'].lower(),\n",
        "          'sentiment_score': prediction['score'],\n",
        "          'topic_bias': bias_topic,\n",
        "          'topic_mentioned': topic,\n",
        "          'topic_score': tweet['topic_probability'],\n",
        "          'party_bias': bias_party,\n",
        "          'party_mentioned': party,\n",
        "      }\n",
        "    return None\n",
        "\n",
        "  # Bias based on negativity/positivity towards a party mentioned in a tweet\n",
        "  def bias_sentiment_party(self, prediction, tweet, single=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      single (bool): Detect only a single party in tweet\n",
        "      \n",
        "    Returns:\n",
        "      bias\n",
        "    \"\"\"\n",
        "    bias = None\n",
        "    party_detected = None\n",
        "    parties_mentioned = 0\n",
        "\n",
        "    for party in self.party_bias:\n",
        "      \n",
        "      for mention in tweet['mentions']:\n",
        "        # Check for mentions or in lemma text\n",
        "        if mention in party['clani'] or party['kratica_stranke'].lower() in tweet['lemma_text'].split(\" \"):\n",
        "          parties_mentioned = parties_mentioned+1\n",
        "          if parties_mentioned == 1:\n",
        "            party_detected = party\n",
        "          break\n",
        "\n",
        "    if single and parties_mentioned == 1 and party_detected is not None:\n",
        "\n",
        "      # If text is neutral\n",
        "      if prediction['label'] == \"Neutral\":\n",
        "        bias = self.labels[2]\n",
        "      # Supports the party\n",
        "      elif prediction['label'] == \"Positive\":\n",
        "        bias = self.labels[party_detected['usmerjenost']]\n",
        "      # Opposes the party\n",
        "      elif prediction['label'] == \"Negative\":\n",
        "        bias = self.labels[int(not party_detected['usmerjenost'])]\n",
        "\n",
        "      return bias, party_detected['kratica_stranke']\n",
        "\n",
        "    # If no parties are mentioned in a tweet\n",
        "    return None, None\n",
        "  \n",
        "  # Bias based on negativity/positivity towards a certain topic of the tweet\n",
        "  def bias_sentiment_topic(self, prediction, tweet):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "\n",
        "    Returns:\n",
        "      bias\n",
        "    \"\"\"\n",
        "    bias = None\n",
        "    topic_detected = None\n",
        "\n",
        "    for topic in self.topic_bias:\n",
        "      if tweet['topic'] == topic:\n",
        "        topic_detected = topic\n",
        "        if prediction['label'] != 'Neutral':\n",
        "          bias = self.labels[self.topic_bias[topic][prediction['label'].lower()]]\n",
        "        break\n",
        "      \n",
        "\n",
        "    return bias, topic_detected\n",
        "  \n",
        "  # User a known member of a party?\n",
        "  def is_user_in_party(self):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "\n",
        "    Returns:\n",
        "      bias\n",
        "    \"\"\"\n",
        "    return\n",
        "  \n",
        "  # Bias based on the user profile\n",
        "  def bias_user(self, prediction, tweet):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      only_desc (bool): Analyze description on user profile only\n",
        "\n",
        "    Returns:\n",
        "      bias\n",
        "    \"\"\"\n",
        "    return\n",
        "\n",
        "  def make_explanation(self, sentiment, bias_party, party, bias_topic, topic):\n",
        "    # TODO\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYWgf6_kjh80"
      },
      "source": [
        "## Sentimentalna analiza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhaWmyCayQbR"
      },
      "outputs": [],
      "source": [
        "# Fetch the config for topic bias\n",
        "\n",
        "topic_bias_path = root_dir + '/configs/topic-bias.json'\n",
        "party_bias_path = root_dir + '/configs/party-bias.json'\n",
        "\n",
        "# Loading bias config\n",
        "topic_bias = load_tweets(topic_bias_path)\n",
        "party_bias = load_tweets(party_bias_path)\n",
        "\n",
        "tweet_tokenizer = AutoTokenizer.from_pretrained(\"EMBEDDIA/sloberta-tweetsentiment\")\n",
        "tweet_model = AutoModelForSequenceClassification.from_pretrained(\"EMBEDDIA/sloberta-tweetsentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBMnhGXKmCCv"
      },
      "outputs": [],
      "source": [
        "pt = TweetimentModel(\"Politics\", tweet_model, tweet_tokenizer, topic_bias, party_bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wuYFz8KYisE"
      },
      "outputs": [],
      "source": [
        "# Predict sentiment on tweets with topic\n",
        "\n",
        "topic_names = ['levo']# 'begunci' , 'religija', 'lgbt', 'splav', 'desno', 'krscanstvo', 'militarizem', 'varnost', 'denacionalizacija', 'levo']\n",
        "\n",
        "for t in topic_names:\n",
        "  tweets_to_predict = load_tweets(f'{root_dir}/postprocess/tweets_{t}.json')\n",
        "\n",
        "  print(f'- Batch length of topic {t}: {len(tweets_to_predict)}')\n",
        "\n",
        "  print(f'- Predicting sentiment on tweets with topic...')\n",
        "  tweets = []\n",
        "  for tweet in tweets_to_predict:\n",
        "    prediction = pt.calculate_biases(tweet)\n",
        "    tweet.pop('topic')\n",
        "    tweet.pop('topic_probability')\n",
        "    tweet['prediction'] = prediction\n",
        "    tweets.append(tweet)\n",
        "  \n",
        "  print(f'- Predicted {len(tweets)} tweets with sentiment')\n",
        "  #print(tweets)\n",
        "\n",
        "  print(f'- Saving tweets to file \"tweets_{t}.json\"...')\n",
        "  save_tweets(tweets, f'{root_dir}/final', f'tweets_{t}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a37e6ef41f9041754ceb21f3dda61e636f9e402d0d6f0468955885061f3c932e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}