{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3mRyXJABvQm"
      },
      "source": [
        "# Modeliranje tem\n",
        "\n",
        "## Okolje\n",
        "\n",
        "Vzpostavitev okolja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h1jsXVwCyHd",
        "outputId": "dcdc062b-6bb1-40fc-a324-5c5a5615f70a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bertopic\n",
            "  Downloading bertopic-0.11.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting hdbscan>=0.8.28\n",
            "  Downloading hdbscan-0.8.28.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 10.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (4.64.0)\n",
            "Requirement already satisfied: pyyaml<6.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (3.13)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (5.5.0)\n",
            "Collecting umap-learn>=0.5.0\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.3.5)\n",
            "Collecting sentence-transformers>=0.4.1\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.28->bertopic) (0.29.32)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.7.0->bertopic) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.13.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 52.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.7.1)\n",
            "Collecting pyyaml<6.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.0->bertopic) (0.56.0)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.39.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2340306 sha256=60de10c8a4e5e6bfd2d9f35a274a8a5faab6d771e1ec49bb07f934d616683429\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/7a/5e/259ccc841c085fc41b99ef4a71e896b62f5161f2bc8a14c97a\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=60f63cd706b0d6cbe24401fb6a7837681bc9a77d709421c82012a954ae0a528e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=b8a591bd87020446b89f0952b84337029b184f4a8cd48cb716d207f8175f179a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.7-py3-none-any.whl size=54286 sha256=5aec2c0327a543df9f28a47042ca2cd8bcf2a9f3310217f74bbc84482ddd00de\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/2a/f8/7bd5dcec71bd5c669f6f574db3113513696b98f3f9b51f496c\n",
            "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, pynndescent, umap-learn, sentence-transformers, hdbscan, bertopic\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed bertopic-0.11.0 hdbscan-0.8.28 huggingface-hub-0.8.1 pynndescent-0.5.7 pyyaml-5.4.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.12.1 transformers-4.21.1 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Tn4J4JIBulX",
        "outputId": "8861e303-db74-4879-e577-f13b62641b85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import os.path\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, pipeline\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JSu7MRUkEUDD"
      },
      "outputs": [],
      "source": [
        "# Setting constants\n",
        "\n",
        "LOCAL = False\n",
        "\n",
        "google_data_dir = \"/content/drive/MyDrive/Diploma/Data\"\n",
        "local_data_dir = \"/data\"\n",
        "\n",
        "root_dir = \"\"\n",
        "if LOCAL:\n",
        "    root_dir = local_data_dir\n",
        "else:\n",
        "    root_dir = google_data_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eHCHjqKD4jR"
      },
      "source": [
        "## Funkcije in razredi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nUGMXt-RE2mY"
      },
      "outputs": [],
      "source": [
        "def load_tweets(file_name):\n",
        "\n",
        "  # Load data\n",
        "  data = []\n",
        "\n",
        "  with open(file_name, 'r', encoding='utf8') as sample_data:\n",
        "    data = json.load(sample_data)\n",
        "\n",
        "  return data\n",
        "\n",
        "def save_tweets(data, dir, file_name):\n",
        "  with open(f'{dir}/{file_name}.json', 'w+', encoding='utf8') as outdata:\n",
        "    json.dump(data, outdata, ensure_ascii=False)\n",
        "\n",
        "def load_and_preprocess(cpipeline, data_dir, only_load, tweet_stop_words=[], tweet_upos=[], min_words=4, verbose=False, debug=False):\n",
        "  d = []\n",
        "  if only_load:\n",
        "    d = load_tweets(data_dir)\n",
        "  else:\n",
        "    d = []#preprocess_tweets(cpipeline, load_tweets(data_dir), tweet_stop_words=tweet_stop_words, tweet_upos=tweet_upos, min_words=min_words, verbose=verbose, debug=debug)\n",
        "  return d\n",
        "\n",
        "def load_labelled_tweets(dir, topic_names, shuffle_arrays=True, random_state=77):\n",
        "  topics = []\n",
        "  for t in topic_names:\n",
        "    with open(f'{dir}/labelled_topics/topic_{t}.json', 'r', encoding='utf8') as topic_data:\n",
        "      data = json.load(topic_data)\n",
        "      topics.extend(data)\n",
        "  \n",
        "  topic_lemmas = []\n",
        "  topic_labels = []\n",
        "\n",
        "  for t in topics:\n",
        "    topic_lemmas.append(t['lemma_text'])\n",
        "    topic_labels.append(t['topic'])\n",
        "\n",
        "  topic_labels = [ topic_names.index(x) for x in topic_labels]\n",
        "\n",
        "  if shuffle_arrays:\n",
        "    shuffle(topic_lemmas, topic_labels, random_state=random_state)\n",
        "  return topic_lemmas, topic_labels\n",
        "\n",
        "\"\"\"\n",
        "Bertopic model for modeling topics\n",
        "\n",
        "\"\"\"\n",
        "class BertopicModel:\n",
        "\n",
        "  def __init__(self, model_name, embed_model, config):\n",
        "    self.model_name = model_name\n",
        "    self.embed_model = embed_model\n",
        "    self.config = config\n",
        "\n",
        "    # Create the Bertopic model with config\n",
        "    self.make_model()\n",
        "\n",
        "  def make_model(self):\n",
        "    self.umap_model = UMAP(**self.config[\"umap_conf\"])\n",
        "    self.hdbscan_model = HDBSCAN(**self.config[\"hdbscan_conf\"])\n",
        "    self.bertopic = BERTopic(embedding_model=self.embed_model, umap_model=self.umap_model, hdbscan_model=self.hdbscan_model, **self.config[\"bertopic_conf\"])\n",
        "\n",
        "  def load_tweet_data(self, tweet_data):\n",
        "    doc_tweet_lemmas = [ t['lemma_text'] for t in tweet_data ]\n",
        "    \n",
        "    self.data = {}\n",
        "    self.data[\"tweets\"] = tweet_data\n",
        "    self.data[\"docs\"] = doc_tweet_lemmas\n",
        "\n",
        "  def load_topic_data(self, topic_docs, topic_labels):\n",
        "    if not hasattr(self, 'data'):\n",
        "      self.data = {}\n",
        "      \n",
        "    self.data[\"docs\"] = topic_docs\n",
        "    self.data[\"labels\"] = topic_labels\n",
        "\n",
        "  def train_model(self, only_fit):\n",
        "    data_keys = self.data.keys()\n",
        "\n",
        "    if \"docs\" in data_keys and not only_fit:\n",
        "      topics, probs = self.bertopic.fit_transform(self.data[\"docs\"])\n",
        "      self.result = {}\n",
        "      self.result[\"topic_ids\"] = topics\n",
        "      self.result[\"topic_probs\"] = probs\n",
        "    elif \"docs\" in data_keys and \"labels\" in data_keys and only_fit:\n",
        "      self.bertopic = self.bertopic.fit(self.data[\"docs\"], y=self.data[\"labels\"])\n",
        "    else:\n",
        "      print(\"Error: Missing data!\")\n",
        "  \n",
        "  def predict(self):\n",
        "    data_keys = self.data.keys()\n",
        "\n",
        "    if \"docs\" in data_keys:\n",
        "      topics, probs = self.bertopic.transform(self.data[\"docs\"])\n",
        "      self.result = {}\n",
        "      self.result[\"topic_ids\"] = topics\n",
        "      self.result[\"topic_probs\"] = probs\n",
        "\n",
        "  def reduce(self, nr):\n",
        "    if hasattr(self, 'data') and hasattr(self, 'result'):\n",
        "      topics, probs = self.bertopic.reduce_topics(self.data[\"docs\"], self.data[\"labels\"], nr_topics=nr)\n",
        "      self.result[\"topic_ids\"] = topics\n",
        "      self.result[\"topic_probs\"] = probs\n",
        "\n",
        "  def merge_topics(self, indexes):\n",
        "    if hasattr(self, 'data'):\n",
        "      self.bertopic.merge_topics(self.data[\"docs\"], self.data[\"labels\"], indexes)\n",
        "\n",
        "  def tweets_from_topic(self, ntopic):\n",
        "    if self.result:\n",
        "      tw = []\n",
        "\n",
        "      for i, x in enumerate(self.result.topic_ids):\n",
        "        if x == ntopic:\n",
        "          tw.append(self.data[\"docs\"][i])\n",
        "\n",
        "      return tw\n",
        "    else:\n",
        "      print(\"Error: Missing data!\")\n",
        "      return []\n",
        "\n",
        "  def collect_topic_indices(self, ntopic, tweet_prob=0.5):\n",
        "    if hasattr(self, 'result'):\n",
        "\n",
        "      tweet_ids = []\n",
        "      for i, x in enumerate(self.result[\"topic_ids\"]):\n",
        "\n",
        "        # Check if topic id and probability higher\n",
        "        if ntopic == x and self.result[\"topic_probs\"][i] > tweet_prob:\n",
        "          tweet_ids.append(i)\n",
        "\n",
        "      return tweet_ids\n",
        "    else:\n",
        "      print(\"Error: Missing data!\")\n",
        "      return []\n",
        "\n",
        "  def find_politic_topics(self, keywords, topn=3, sim_threshold=0.5, tweet_prob=0.5, include_prob=False):\n",
        "    if hasattr(self, 'bertopic'):\n",
        "      indices = set()\n",
        "\n",
        "      # Find relating topics\n",
        "      for keyword in keywords:\n",
        "        sim_ids, sim_probs = self.bertopic.find_topics(keyword, top_n=topn)\n",
        "\n",
        "        # Filter based on similarity\n",
        "        sim_topics = [ sim_ids[i] for i, x in enumerate(sim_probs) if x > sim_threshold ]\n",
        "\n",
        "        if len(sim_topics) > 0:\n",
        "          for topic in sim_topics:\n",
        "            indices.update(self.collect_topic_indices(topic, tweet_prob=tweet_prob))\n",
        "      \n",
        "      tweet_docs = []\n",
        "      for i in indices:\n",
        "        tdoc = self.data[\"tweets\"][i]\n",
        "        if include_prob:\n",
        "          tdoc[\"topic_probability\"] = self.result[\"topic_probs\"][i]\n",
        "\n",
        "        tweet_docs.append(tdoc)\n",
        "\n",
        "      return tweet_docs\n",
        "    else:\n",
        "      print(\"Error: Missing data!\")\n",
        "      return []\n",
        "\n",
        "  def visualize(self, t='distance_map'):\n",
        "    if hasattr(self, 'bertopic'):\n",
        "      #return self.bertopic.visualize_topics()\n",
        "      if t == 'barchart':\n",
        "        return self.bertopic.visualize_barchart()\n",
        "      elif t == 'hierarchy':\n",
        "        return self.bertopic.visualize_hierarchy()\n",
        "      elif t == 'heatmap':\n",
        "        return self.bertopic.visualize_heatmap()\n",
        "      elif t == 'term_rank':\n",
        "        return self.bertopic.visualize_term_rank()\n",
        "      else:\n",
        "        return self.bertopic.visualize_topics()\n",
        "      #elif t == 'documents':\n",
        "      #  self.bertopic.visualize_documents()\n",
        "    else:\n",
        "      print(\"Error: Model not yet initiated!\")\n",
        "\n",
        "  def save_model(self, model_dir):\n",
        "    self.bertopic.save(str(model_dir + self.model_name))\n",
        "  \n",
        "  def load_model(self, model_dir):\n",
        "    self.bertopic.load(str(model_dir + self.model_name), embedding_model=self.embed_model)\n",
        "\n",
        "def label_politic_tweets(model : BertopicModel, topic_info, data_dir, topn=3, n_sim_subtopics=3, save_tweets=False, verbose=True):\n",
        "\n",
        "  if verbose:\n",
        "    print(f'-- Collected batch topic distribution summary:')\n",
        "\n",
        "  sim_topics = similar_topics(model, topic_info, topn=topn, n_sim_subtopics=n_sim_subtopics)\n",
        "\n",
        "  tweets = model.data['tweets']\n",
        "  labels = model.result['topic_ids']\n",
        "  probs = model.result['topic_probs']\n",
        "\n",
        "  for i in range(len(tweets)):\n",
        "    tweet = tweets[i]\n",
        "    label = labels[i]\n",
        "    prob = probs[i]\n",
        "\n",
        "    most_likely_topic = None\n",
        "    most_likely_prob = 0\n",
        "\n",
        "    for st in sim_topics:\n",
        "      for sbt, prob in sim_topics[st]:\n",
        "        if sbt == label and prob > most_likely_prob:\n",
        "          most_likely_topic = st\n",
        "          most_likely_prob = prob\n",
        "\n",
        "\n",
        "    if most_likely_topic is not None and topic_info[most_likely_topic]['strict']:\n",
        "      kw = []\n",
        "      kw.extend(topic_info[most_likely_topic]['keywords'])\n",
        "      kw.extend(topic_info[most_likely_topic]['search_term'])\n",
        "\n",
        "      founds = False\n",
        "      for key in kw:\n",
        "        if key in tweet['lemma_text']:\n",
        "          tweet['topic'] = most_likely_topic\n",
        "          tweet['topic_probability'] = prob\n",
        "          founds = True\n",
        "          break\n",
        "      \n",
        "      if not founds:\n",
        "        tweet['topic'] = None\n",
        "        tweet['topic_probability'] = 0\n",
        "\n",
        "    else:\n",
        "      tweet['topic'] = most_likely_topic\n",
        "      tweet['topic_probability'] = prob\n",
        "\n",
        "  if save_tweets:\n",
        "    for tp in topic_info:\n",
        "      t = list(filter(lambda x: x['topic'] == tp, tweets))\n",
        "      if verbose:\n",
        "        print(f'-- {tp} : {len(t)}')\n",
        "      overwrite_labelled_topics(tp, t, data_dir)\n",
        "\n",
        "  return model.data['tweets']\n",
        "\n",
        "def similar_topics(model : BertopicModel, topic_info, topn=3, n_sim_subtopics=3) -> dict:\n",
        "    \n",
        "  sim_topics = {}\n",
        "\n",
        "  for topic in topic_info:\n",
        "    tt = topic_info[topic]\n",
        "\n",
        "    tpcs1 = {}\n",
        "    for keyword in tt['search_term']:\n",
        "      sims = model.bertopic.find_topics(keyword, top_n=topn)\n",
        "\n",
        "      sims = tuple(zip(sims[0], sims[1]))\n",
        "\n",
        "      tpcs2 = dict((x, y) for x, y in sims)\n",
        "\n",
        "      tpcs1 = {\n",
        "        key: tpcs1.get(key, 0) + tpcs2.get(key, 0) for key in set(tpcs1) | set(tpcs2)\n",
        "      }\n",
        "    \n",
        "    # Normalize\n",
        "    mv = max(tpcs1.values())\n",
        "    for kj in tpcs1:\n",
        "      tpcs1[kj] = float(tpcs1[kj] / mv)\n",
        "      \n",
        "    subtopics = []\n",
        "    for i in range(n_sim_subtopics):\n",
        "      if tpcs1:\n",
        "        k1 = max(tpcs1, key=tpcs1.get)\n",
        "        if k1 != -1:\n",
        "          subtopics.append((k1, tpcs1[k1]))\n",
        "        tpcs1.pop(k1)\n",
        "    \n",
        "    sim_topics[topic] = subtopics\n",
        "  \n",
        "  return sim_topics\n",
        "\n",
        "def overwrite_labelled_topics(file_topic, topic_tweets, data_dir):\n",
        "    data=[]\n",
        "    with open(f'{data_dir}/labelled_topics/topic_{file_topic}.json', 'r', encoding='utf8') as topic_data:\n",
        "      data = json.load(topic_data)\n",
        "      data.extend(topic_tweets)\n",
        "    with open(f'{data_dir}/labelled_topics/topic_{file_topic}.json', 'w', encoding='utf8') as topic_data_n:\n",
        "      json.dump(data, topic_data_n, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6wDbqNgPjAsX"
      },
      "outputs": [],
      "source": [
        "# Setting configuration\n",
        "\n",
        "# Path to preprocessed tweet data\n",
        "\n",
        "YEAR = 2021\n",
        "EPOCH = 2\n",
        "BATCH = 1\n",
        "\n",
        "tweet_data_path = f'preprocess/{YEAR}-{EPOCH}/{YEAR}_{EPOCH}_{BATCH}.json'\n",
        "\n",
        "# Path to save labelled tweet data\n",
        "SAVING = True\n",
        "tweet_save_path = f'stpt/{YEAR}-{EPOCH}'\n",
        "\n",
        "# Verbose\n",
        "VERBOSE = True\n",
        "\n",
        "# Imported configurations\n",
        "politics_seed_topic = [[\"politik\", \"politika\", \"političen\"],[\"vlada\", \"vladati\", \"država\"],[\"komunist\", \"komunističen\", \"komunizem\"],[\"socializem\", \"socialen\", \"sociala\"],[\"fašisti\", \"fašističen\", \"fašizem\"],[\"levičar\", \"levičarski\", \"levica\"],[\"desničar\", \"desničarski\", \"desnica\", \"janez\", \"jj\", \"sds\"],[\"nosečnost\", \"nosečnica\", \"splav\", \"ženska\"],[\"migrant\", \"migriranje\", \"beg\", \"begunec\"],[\"musliman\", \"islam\", \"islamist\", \"islamist\", \"ekstremist\"],[\"kriminal\", \"kiminalec\", \"zločinec\"],[\"lgbtq\", \"istospolni\", \"lgbt\", \"spol\"]]\n",
        "\n",
        "topic_info = {\n",
        "    'begunci': {\n",
        "        'search_term': [\"begunec\", \"migrant\", \"migrantski\"],\n",
        "        'keywords': [],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'lgbtq': {\n",
        "        'search_term': [\"lgbtq\", \"lgbt\", \"istospolno\"],\n",
        "        'keywords': [],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'religija': {\n",
        "        'search_term': [\"islam\", \"musliman\", \"vera\"],\n",
        "        'keywords': [\"religija\", \"dzihadist\"],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'splav': {\n",
        "        'search_term': [\"splav\"],\n",
        "        'keywords': [\"kontracepcija\"],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'desno': {\n",
        "        'search_term': [\"desnica\", \"desno\", \"jj\", \"sds\"],\n",
        "        'keywords': [\"jansa\", \"desnicar\", \"janša\"],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'levo': {\n",
        "        'search_term': [\"levica\", \"levicar\", \"lev\"],\n",
        "        'keywords': [\"levicarski\", \"levičar\", \"mesec\"],\n",
        "        'strict': True,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    },\n",
        "    'politika': {\n",
        "        'search_term': [\"politika\", \"politicen\", \"vlada\"],\n",
        "        'keywords': [],\n",
        "        'strict': False,\n",
        "        'sim_threshold': 0.2,\n",
        "        'tweet_prob': 0.5\n",
        "    }\n",
        "}\n",
        "\n",
        "# Preprocessing configuration\n",
        "preprocess_config = {\n",
        "    'min_words': 4,\n",
        "    'verbose': True,\n",
        "    'debug': False,\n",
        "    'tweet_upos': ['PUNCT', 'NUM', 'SYM', 'CCONJ', 'INTJ'],\n",
        "    'tweet_stop_words': ['http', 'https', 'rt', 'oz']\n",
        "}\n",
        "\n",
        "# Bertopic first layer configuration\n",
        "bertopic_FL_config = {\n",
        "    'bertopic_conf': {\n",
        "        \"top_n_words\": 10,\n",
        "        \"min_topic_size\": 20,\n",
        "        \"seed_topic_list\": politics_seed_topic\n",
        "    },\n",
        "    'umap_conf': {\n",
        "        \"n_neighbors\": 15,\n",
        "        \"n_components\": 10,\n",
        "        \"metric\": 'cosine'\n",
        "    },\n",
        "    'hdbscan_conf': {\n",
        "        \"min_cluster_size\": 10,\n",
        "        \"metric\": 'euclidean',\n",
        "        \"prediction_data\": True\n",
        "    },\n",
        "    'sim_threshold': 0.5,\n",
        "    'tweet_prob': 0.5\n",
        "}\n",
        "\n",
        "# Bertopic second layer configuration\n",
        "bertopic_SL_config = {\n",
        "    'bertopic_conf': {\n",
        "        \"top_n_words\": 10,\n",
        "        \"min_topic_size\": 20,\n",
        "        #\"nr_topics\": 8\n",
        "    },\n",
        "    'umap_conf': {\n",
        "        \"n_neighbors\": 20,\n",
        "        \"n_components\": 10,\n",
        "        \"metric\": 'cosine'\n",
        "    },\n",
        "    'hdbscan_conf': {\n",
        "        \"min_cluster_size\": 15,\n",
        "        \"metric\": 'euclidean',\n",
        "        \"prediction_data\": True\n",
        "    },\n",
        "    'topn': 3,\n",
        "    'n_sim_subtopics': 3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4ba252af876d4c16b58ed5a2d3f9baeb",
            "176fc252b8aa422eb9c130bed0e47c5b",
            "86d59bbdc59b47d9ae98c8687d7c2609",
            "a99d880cab16471691a623af9a9d42f0",
            "011ad6884e574edc9931ef6177e6ef9a",
            "02b7c594a026406ab9e1b96d3f61362b",
            "07656b3341624a61ab67970131f03e14",
            "f0bdcfd9d4154a1e823d0503a7aa2904",
            "96ed1cdbf25040e1859cb43f90183b8a",
            "afd54f0b24f342f980068c843d3df0cd",
            "90491e8c0df34c68afc1136437fcb1c7",
            "0150168107f040adbbd56aee44e87e01",
            "9892ade33bdc47f4816c2677be94e6dd",
            "1570e94c893e4ddbae90de5d7ab70043",
            "3a0780dec2c3461fa279d146c9d4de25",
            "013b3987c30440628324be35dd8db6ee",
            "45aaaf115e9c4f7d8c31265d9813dec2",
            "5294cdbbac4f45f68754c6498d00c739",
            "f82cd73a41f840afa98b0288bb15870c",
            "56374dabdee14d6d8e31c6eea24cc4d3",
            "80f4171fd07b4b548f0263d48b9748e6",
            "736142c5ded54ac79e2d76e29a89b75a"
          ]
        },
        "id": "K11pc8m4jAsY",
        "outputId": "896bfa96-0519-425c-dc33-08d31aecb030"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ba252af876d4c16b58ed5a2d3f9baeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/520 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0150168107f040adbbd56aee44e87e01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Loading models\n",
        "\n",
        "slobert_model = AutoModelForMaskedLM.from_pretrained(\"EMBEDDIA/sloberta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWp10rl9jAsZ",
        "outputId": "cb201e70-e009-4fcc-a9d2-6c3def1199da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Batch summary:\n",
            "-- Batch length: 3542\n",
            "- First layer of topic modeling...\n",
            "- Training 1st layer of Bertopic model...\n",
            "- Saving 1st layer of Bertopic model...\n",
            "- Batch of general politics summary:\n",
            "-- Batch length: 932\n",
            "- Saving STPT in file stpt/2021-2...\n",
            "- Second layer of topic modeling...\n",
            "- Training 2nd layer of Bertopic model...\n",
            "- Saving 2nd layer of Bertopic model...\n",
            "- Predicting new instances on second layer topic modeling...\n",
            "- Labelling and saving topic tweets...\n",
            "-- Collected batch topic distribution summary:\n",
            "-- begunci : 15\n",
            "-- lgbtq : 4\n",
            "-- religija : 1\n",
            "-- splav : 0\n",
            "-- desno : 13\n",
            "-- levo : 27\n",
            "-- politika : 253\n"
          ]
        }
      ],
      "source": [
        "# MAIN CODE\n",
        "\n",
        "# Load preprocessed tweets\n",
        "preprocessed_tweet_data = load_and_preprocess(None, f'{root_dir}/{tweet_data_path}', True)\n",
        "\n",
        "# Print summary if verbose\n",
        "if VERBOSE:\n",
        "  print(f'- Batch summary:')\n",
        "  print(f'-- Batch length: {len(preprocessed_tweet_data)}')\n",
        "  \n",
        "# First layer of topic modeling\n",
        "print(f'- First layer of topic modeling...')\n",
        "\n",
        "# Create Bertopic model (1st layer)\n",
        "bt_fl_model = BertopicModel('Bertopic_FL', embed_model=slobert_model, config=bertopic_FL_config)\n",
        "\n",
        "# Load twitter data\n",
        "bt_fl_model.load_tweet_data(preprocessed_tweet_data)\n",
        "\n",
        "if VERBOSE:\n",
        "  print(f'- Training 1st layer of Bertopic model...')\n",
        "# Train the model\n",
        "bt_fl_model.train_model(only_fit=False)\n",
        "\n",
        "if SAVING:\n",
        "  if VERBOSE:\n",
        "    print(f'- Saving 1st layer of Bertopic model...')\n",
        "  # Save model\n",
        "  bt_fl_model.save_model(f'{root_dir}/models')\n",
        "\n",
        "# Extract general politic topics\n",
        "topics_to_extract = [item for sublist in bertopic_FL_config['bertopic_conf']['seed_topic_list'] for item in sublist]\n",
        "extracted_tweets = bt_fl_model.find_politic_topics(topics_to_extract, sim_threshold=bertopic_FL_config['sim_threshold'], tweet_prob=bertopic_FL_config['tweet_prob'])\n",
        "\n",
        "if VERBOSE:\n",
        "  print(f'- Batch of general politics summary:')\n",
        "  print(f'-- Batch length: {len(extracted_tweets)}')\n",
        "\n",
        "# Save STP tweets\n",
        "if SAVING:\n",
        "  if VERBOSE:\n",
        "    print(f'- Saving STPT in file {tweet_save_path}...')\n",
        "  save_tweets(extracted_tweets, dir=f'{root_dir}/{tweet_save_path}', file_name=f'{YEAR}_{EPOCH}_{BATCH}')\n",
        "\n",
        "\n",
        "# Second layer of topic modeling\n",
        "if VERBOSE:\n",
        "  print(f'- Second layer of topic modeling...')\n",
        "\n",
        "# Get training data\n",
        "topic_names = [item for item in topic_info]\n",
        "X, y = load_labelled_tweets(root_dir, topic_names)\n",
        "\n",
        "# Create Bertopic model (2nd layer)\n",
        "bt_sl_model = BertopicModel('Bertopic_SL', embed_model=slobert_model, config=bertopic_SL_config)\n",
        "\n",
        "# Load training data\n",
        "bt_sl_model.load_topic_data(X, y)\n",
        "\n",
        "# Train model with training data\n",
        "if VERBOSE:\n",
        "  print(f'- Training 2nd layer of Bertopic model...')\n",
        "bt_sl_model.train_model(only_fit=True)\n",
        "\n",
        "# Saving the SL model\n",
        "if SAVING:\n",
        "  if VERBOSE:\n",
        "    print(f'- Saving 2nd layer of Bertopic model...')\n",
        "  bt_sl_model.save_model(f'{root_dir}/models')\n",
        "\n",
        "# Load extracted tweets (test data)\n",
        "bt_sl_model.load_tweet_data(extracted_tweets)\n",
        "\n",
        "if VERBOSE:\n",
        "  print(f'- Predicting new instances on second layer topic modeling...')\n",
        "\n",
        "# Predict new instances on test data\n",
        "bt_sl_model.predict()\n",
        "\n",
        "# Label new instances & overwrite\n",
        "if VERBOSE:\n",
        "  print(f'- Labelling and saving topic tweets...')\n",
        "labelled_tweets = label_politic_tweets(bt_sl_model, topic_info, root_dir, topn=bertopic_SL_config['topn'], n_sim_subtopics=bertopic_SL_config['n_sim_subtopics'], save_tweets=SAVING, verbose=VERBOSE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Topic modeling.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a37e6ef41f9041754ceb21f3dda61e636f9e402d0d6f0468955885061f3c932e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "011ad6884e574edc9931ef6177e6ef9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "013b3987c30440628324be35dd8db6ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0150168107f040adbbd56aee44e87e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9892ade33bdc47f4816c2677be94e6dd",
              "IPY_MODEL_1570e94c893e4ddbae90de5d7ab70043",
              "IPY_MODEL_3a0780dec2c3461fa279d146c9d4de25"
            ],
            "layout": "IPY_MODEL_013b3987c30440628324be35dd8db6ee"
          }
        },
        "02b7c594a026406ab9e1b96d3f61362b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07656b3341624a61ab67970131f03e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1570e94c893e4ddbae90de5d7ab70043": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82cd73a41f840afa98b0288bb15870c",
            "max": 442838427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56374dabdee14d6d8e31c6eea24cc4d3",
            "value": 442838427
          }
        },
        "176fc252b8aa422eb9c130bed0e47c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b7c594a026406ab9e1b96d3f61362b",
            "placeholder": "​",
            "style": "IPY_MODEL_07656b3341624a61ab67970131f03e14",
            "value": "Downloading config.json: 100%"
          }
        },
        "3a0780dec2c3461fa279d146c9d4de25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80f4171fd07b4b548f0263d48b9748e6",
            "placeholder": "​",
            "style": "IPY_MODEL_736142c5ded54ac79e2d76e29a89b75a",
            "value": " 422M/422M [00:08&lt;00:00, 35.0MB/s]"
          }
        },
        "45aaaf115e9c4f7d8c31265d9813dec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba252af876d4c16b58ed5a2d3f9baeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_176fc252b8aa422eb9c130bed0e47c5b",
              "IPY_MODEL_86d59bbdc59b47d9ae98c8687d7c2609",
              "IPY_MODEL_a99d880cab16471691a623af9a9d42f0"
            ],
            "layout": "IPY_MODEL_011ad6884e574edc9931ef6177e6ef9a"
          }
        },
        "5294cdbbac4f45f68754c6498d00c739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56374dabdee14d6d8e31c6eea24cc4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "736142c5ded54ac79e2d76e29a89b75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80f4171fd07b4b548f0263d48b9748e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d59bbdc59b47d9ae98c8687d7c2609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bdcfd9d4154a1e823d0503a7aa2904",
            "max": 520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ed1cdbf25040e1859cb43f90183b8a",
            "value": 520
          }
        },
        "90491e8c0df34c68afc1136437fcb1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96ed1cdbf25040e1859cb43f90183b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9892ade33bdc47f4816c2677be94e6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45aaaf115e9c4f7d8c31265d9813dec2",
            "placeholder": "​",
            "style": "IPY_MODEL_5294cdbbac4f45f68754c6498d00c739",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a99d880cab16471691a623af9a9d42f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd54f0b24f342f980068c843d3df0cd",
            "placeholder": "​",
            "style": "IPY_MODEL_90491e8c0df34c68afc1136437fcb1c7",
            "value": " 520/520 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "afd54f0b24f342f980068c843d3df0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0bdcfd9d4154a1e823d0503a7aa2904": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82cd73a41f840afa98b0288bb15870c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
